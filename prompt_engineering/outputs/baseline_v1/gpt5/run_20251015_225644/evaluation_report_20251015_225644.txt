HATE SPEECH DETECTION - STRATEGY EVALUATION REPORT
============================================================
Generated: 2025-10-15 22:59:49
Model: gpt-5
Prompt Template File: baseline_v1_gpt5.json
Data Source: canned_100_size_varied
Total samples tested: 100

EXECUTION DETAILS:
--------------------
Command Line: prompt_runner.py --data-source canned_100_size_varied --strategies all --output-dir outputs\baseline_v1\gpt5 --max-workers 15 --batch-size 8 --prompt-template-file baseline_v1_gpt5.json --model gpt-5

SAMPLE TEST DATA:
--------------------
1. Text: <user> i am trynna make it a non gay offensive slur lol i only call non gays faggots you a faggot if...
   Label: normal

2. Text: those muslims are terrible people! they are brainwashed by extremists! they need to convert to chris...
   Label: hate

3. Text: kate, what was the reason behind your decision to separate? okay. in 2009 i was in a very public rel...
   Label: normal

... (middle samples) ...
50. Text: every day life is so much more meaningful if you actually understand the art and culture of the midd...
   Label: normal

51. Text: clc first win and chuu teaser today is for the homosexuals
   Label: normal

... (final samples) ...
99. Text: middle east is the richest land in the world
   Label: normal

100. Text: When I met him I was living in West Hollywood, but I was still in the closet,
   Label: normal

[Showing sample of 7 out of 100 total test samples]


STRATEGY PERFORMANCE:
-------------------------

BASELINE_CONSERVATIVE Strategy:
  Accuracy:  0.545
  Precision: 0.571
  Recall:    0.170
  F1-Score:  0.262
  Confusion Matrix: TP=8, TN=46, FP=6, FN=39

BASELINE_STANDARD Strategy:
  Accuracy:  0.610
  Precision: 0.600
  Recall:    0.511
  F1-Score:  0.552
  Confusion Matrix: TP=24, TN=37, FP=16, FN=23

BASELINE_BALANCED Strategy:
  Accuracy:  0.570
  Precision: 0.550
  Recall:    0.468
  F1-Score:  0.506
  Confusion Matrix: TP=22, TN=35, FP=18, FN=25


BIAS AND FAIRNESS METRICS BY PERSONA:
----------------------------------------
üìä FPR = False Positive Rate (benign‚Üíhate misclassification)
üìä FNR = False Negative Rate (hate‚Üíbenign missed detection)
üéØ Lower rates indicate better fairness across personas

BASELINE_CONSERVATIVE Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 49
     FPR: 0.069 (FP=2, TN=27)
     FNR: 0.684 (FN=13, TP=6)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 22
     FPR: 0.200 (FP=2, TN=8)
     FNR: 0.917 (FN=11, TP=1)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 29
     FPR: 0.154 (FP=2, TN=11)
     FNR: 0.938 (FN=15, TP=1)
     Fairness: ‚ö†Ô∏è REVIEW


BASELINE_STANDARD Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 49
     FPR: 0.300 (FP=9, TN=21)
     FNR: 0.474 (FN=9, TP=10)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 22
     FPR: 0.200 (FP=2, TN=8)
     FNR: 0.500 (FN=6, TP=6)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 29
     FPR: 0.385 (FP=5, TN=8)
     FNR: 0.500 (FN=8, TP=8)
     Fairness: ‚ö†Ô∏è REVIEW


BASELINE_BALANCED Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 49
     FPR: 0.367 (FP=11, TN=19)
     FNR: 0.368 (FN=7, TP=12)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 22
     FPR: 0.300 (FP=3, TN=7)
     FNR: 0.667 (FN=8, TP=4)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 29
     FPR: 0.308 (FP=4, TN=9)
     FNR: 0.625 (FN=10, TP=6)
     Fairness: ‚ö†Ô∏è REVIEW
