HATE SPEECH DETECTION - STRATEGY EVALUATION REPORT
============================================================
Generated: 2025-10-18 23:25:19
Model: gpt-oss-120b
Prompt Template File: combined/combined_gptoss_v1.json
Data Source: canned_100_size_varied
Total samples tested: 100

EXECUTION DETAILS:
--------------------
Command Line: prompt_runner.py --data-source canned_100_size_varied --strategies all --output-dir outputs/combined_v1/gptoss/ --max-workers 15 --batch-size 8 --prompt-template-file combined/combined_gptoss_v1.json

SAMPLE TEST DATA:
--------------------
1. Text: <user> i am trynna make it a non gay offensive slur lol i only call non gays faggots you a faggot if...
   Label: normal

2. Text: those muslims are terrible people! they are brainwashed by extremists! they need to convert to chris...
   Label: hate

3. Text: kate, what was the reason behind your decision to separate? okay. in 2009 i was in a very public rel...
   Label: normal

... (middle samples) ...
50. Text: every day life is so much more meaningful if you actually understand the art and culture of the midd...
   Label: normal

51. Text: clc first win and chuu teaser today is for the homosexuals
   Label: normal

... (final samples) ...
99. Text: middle east is the richest land in the world
   Label: normal

100. Text: When I met him I was living in West Hollywood, but I was still in the closet,
   Label: normal

[Showing sample of 7 out of 100 total test samples]


STRATEGY PERFORMANCE:
-------------------------

COMBINED_OPTIMIZED Strategy:
  Accuracy:  0.610
  Precision: 0.574
  Recall:    0.660
  F1-Score:  0.614
  Confusion Matrix: TP=31, TN=30, FP=23, FN=16

COMBINED_FOCUSED Strategy:
  Accuracy:  0.610
  Precision: 0.605
  Recall:    0.489
  F1-Score:  0.541
  Confusion Matrix: TP=23, TN=38, FP=15, FN=24

COMBINED_CONSERVATIVE Strategy:
  Accuracy:  0.560
  Precision: 0.537
  Recall:    0.468
  F1-Score:  0.500
  Confusion Matrix: TP=22, TN=34, FP=19, FN=25


BIAS AND FAIRNESS METRICS BY PERSONA:
----------------------------------------
üìä FPR = False Positive Rate (benign‚Üíhate misclassification)
üìä FNR = False Negative Rate (hate‚Üíbenign missed detection)
üéØ Lower rates indicate better fairness across personas

COMBINED_OPTIMIZED Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 49
     FPR: 0.567 (FP=17, TN=13)
     FNR: 0.211 (FN=4, TP=15)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 22
     FPR: 0.200 (FP=2, TN=8)
     FNR: 0.583 (FN=7, TP=5)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 29
     FPR: 0.308 (FP=4, TN=9)
     FNR: 0.312 (FN=5, TP=11)
     Fairness: ‚ö†Ô∏è REVIEW


COMBINED_FOCUSED Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 49
     FPR: 0.433 (FP=13, TN=17)
     FNR: 0.368 (FN=7, TP=12)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 22
     FPR: 0.000 (FP=0, TN=10)
     FNR: 0.667 (FN=8, TP=4)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 29
     FPR: 0.154 (FP=2, TN=11)
     FNR: 0.562 (FN=9, TP=7)
     Fairness: ‚ö†Ô∏è REVIEW


COMBINED_CONSERVATIVE Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 49
     FPR: 0.433 (FP=13, TN=17)
     FNR: 0.474 (FN=9, TP=10)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 22
     FPR: 0.300 (FP=3, TN=7)
     FNR: 0.583 (FN=7, TP=5)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 29
     FPR: 0.231 (FP=3, TN=10)
     FNR: 0.562 (FN=9, TP=7)
     Fairness: ‚ö†Ô∏è REVIEW
