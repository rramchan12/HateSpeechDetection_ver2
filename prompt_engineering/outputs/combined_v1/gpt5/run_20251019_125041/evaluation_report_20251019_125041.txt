HATE SPEECH DETECTION - STRATEGY EVALUATION REPORT
============================================================
Generated: 2025-10-19 12:57:33
Model: gpt-5
Prompt Template File: combined/combined_gpt5_v1.json
Data Source: canned_100_size_varied
Total samples tested: 100

EXECUTION DETAILS:
--------------------
Command Line: prompt_runner.py --data-source canned_100_size_varied --strategies all --output-dir outputs/combined_v1/gpt5/ --max-workers 15 --batch-size 8 --prompt-template-file combined/combined_gpt5_v1.json --model gpt-5

SAMPLE TEST DATA:
--------------------
1. Text: <user> i am trynna make it a non gay offensive slur lol i only call non gays faggots you a faggot if...
   Label: normal

2. Text: those muslims are terrible people! they are brainwashed by extremists! they need to convert to chris...
   Label: hate

3. Text: kate, what was the reason behind your decision to separate? okay. in 2009 i was in a very public rel...
   Label: normal

... (middle samples) ...
50. Text: every day life is so much more meaningful if you actually understand the art and culture of the midd...
   Label: normal

51. Text: clc first win and chuu teaser today is for the homosexuals
   Label: normal

... (final samples) ...
99. Text: middle east is the richest land in the world
   Label: normal

100. Text: When I met him I was living in West Hollywood, but I was still in the closet,
   Label: normal

[Showing sample of 7 out of 100 total test samples]


STRATEGY PERFORMANCE:
-------------------------

COMBINED_OPTIMIZED Strategy:
  Accuracy:  0.616
  Precision: 0.587
  Recall:    0.587
  F1-Score:  0.587
  Confusion Matrix: TP=27, TN=34, FP=19, FN=19

COMBINED_FOCUSED Strategy:
  Accuracy:  0.620
  Precision: 0.622
  Recall:    0.489
  F1-Score:  0.548
  Confusion Matrix: TP=23, TN=39, FP=14, FN=24

COMBINED_CONSERVATIVE Strategy:
  Accuracy:  0.580
  Precision: 0.571
  Recall:    0.426
  F1-Score:  0.488
  Confusion Matrix: TP=20, TN=38, FP=15, FN=27


BIAS AND FAIRNESS METRICS BY PERSONA:
----------------------------------------
üìä FPR = False Positive Rate (benign‚Üíhate misclassification)
üìä FNR = False Negative Rate (hate‚Üíbenign missed detection)
üéØ Lower rates indicate better fairness across personas

COMBINED_OPTIMIZED Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 49
     FPR: 0.367 (FP=11, TN=19)
     FNR: 0.368 (FN=7, TP=12)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 22
     FPR: 0.300 (FP=3, TN=7)
     FNR: 0.455 (FN=5, TP=6)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 29
     FPR: 0.385 (FP=5, TN=8)
     FNR: 0.438 (FN=7, TP=9)
     Fairness: ‚ö†Ô∏è REVIEW


COMBINED_FOCUSED Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 49
     FPR: 0.267 (FP=8, TN=22)
     FNR: 0.579 (FN=11, TP=8)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 22
     FPR: 0.200 (FP=2, TN=8)
     FNR: 0.500 (FN=6, TP=6)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 29
     FPR: 0.308 (FP=4, TN=9)
     FNR: 0.438 (FN=7, TP=9)
     Fairness: ‚ö†Ô∏è REVIEW


COMBINED_CONSERVATIVE Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 49
     FPR: 0.300 (FP=9, TN=21)
     FNR: 0.526 (FN=10, TP=9)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 22
     FPR: 0.200 (FP=2, TN=8)
     FNR: 0.583 (FN=7, TP=5)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 29
     FPR: 0.308 (FP=4, TN=9)
     FNR: 0.625 (FN=10, TP=6)
     Fairness: ‚ö†Ô∏è REVIEW
