{
  "strategies": {
    "baseline": {
      "name": "baseline",
      "description": "Baseline classification approach without persona or policy context",
      "system_prompt": "You are a content moderation assistant trained to classify social media posts as either 'hate' or 'normal'.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text contains hate speech\n- Use EXACTLY 'normal' if the text does not contain hate speech\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nBase your decision on general understanding of hateful language and social norms.",
      "user_template": "Classify the following text as either 'hate' or 'normal'.\n\nText: \"{text}\"\n\nRespond in JSON format: {{\"classification\": \"[hate/normal]\", \"rationale\": \"[brief explanation]\"}}",
      "parameters": {
        "max_tokens": 512,
        "temperature": 0.1,
        "top_p": 1.0,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "response_format": "json_object"
      }
    },
    "policy": {
      "name": "policy",
      "description": "Policy-based content moderation using platform guidelines",
      "system_prompt": "You are a content moderation assistant responsible for evaluating social media posts for potential hate speech violations using platform guidelines.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates the hate speech policy\n- Use EXACTLY 'normal' if the text does not violate the hate speech policy\n- NO other labels are allowed\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nAlways base your judgment strictly on the policy definition provided.",
      "user_template": "POLICY: According to our platform's hate speech policy, content that attacks or demeans people based on race, religion, gender, or sexual orientation is prohibited.\n\nAnalyze this text for hate speech policy violations.\n\nText: \"{text}\"\n\nClassify as EXACTLY one of these labels:\n- hate (if the text violates the hate speech policy)\n- normal (if the text does not violate the hate speech policy)\n\nRespond in JSON format: {{\"classification\": \"[hate/normal]\", \"rationale\": \"[brief explanation]\"}}",
      "parameters": {
        "max_tokens": 768,
        "temperature": 0.2,
        "top_p": 0.9,
        "frequency_penalty": 0.1,
        "presence_penalty": 0.1,
        "response_format": "json_object"
      }
    },
    "persona": {
      "name": "persona",
      "description": "Persona-based analysis using multiple perspective evaluation",
      "system_prompt": "You are a content moderation assistant evaluating social media posts for hate speech using multiple perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text contains hate speech from any perspective\n- Use EXACTLY 'normal' if the text does not contain hate speech from any perspective\n- NO other labels are allowed\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nConsider multiple viewpoints but provide one consolidated decision.",
      "user_template": "Consider multiple perspectives when analyzing this text for hate speech:\n\nPerspective 1 (Middle Eastern person): Would this be considered offensive or hateful?\nPerspective 2 (Conservative viewpoint): How would this be classified?\n\nText: \"{text}\"\n\nProvide a consolidated classification as EXACTLY one of these labels:\n- hate (if the text contains hate speech from any perspective)\n- normal (if the text does not contain hate speech from any perspective)\n\nRespond in JSON format: {{\"classification\": \"[hate/normal]\", \"rationale\": \"[brief explanation]\"}}",
      "parameters": {
        "max_tokens": 512,
        "temperature": 0.1,
        "top_p": 1.0,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "response_format": "json_object"
      }
    },
    "combined": {
      "name": "combined",
      "description": "Combined policy and persona approach with conservative hate detection",
      "system_prompt": "You are a content moderation assistant evaluating social media posts for hate speech using both policy guidelines and multiple perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates policy OR is offensive from any perspective\n- Use EXACTLY 'normal' if the text does not violate policy AND is not offensive from any perspective\n- NO other labels are allowed\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n- Use conservative approach: any hate indication results in 'hate' classification",
      "user_template": "POLICY: Hate speech is defined as content that attacks or demeans people based on race, religion, gender, or sexual orientation.\n\nAnalyze this text using both policy and multiple perspectives:\n\nPerspective 1 (Young Mexican student): Per the policy, is this hate speech?\nPerspective 2 (Young gay man): Per the policy, how would you classify this?\n\nText: \"{text}\"\n\nProvide a consolidated policy decision as EXACTLY one of these labels:\n- hate (if text violates policy OR is offensive from any perspective)\n- normal (if text does not violate policy AND is not offensive from any perspective)\n\nRespond in JSON format: {{\"classification\": \"[hate/normal]\", \"rationale\": \"[brief explanation]\"}}",
      "parameters": {
        "max_tokens": 512,
        "temperature": 0.1,
        "top_p": 1.0,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0,
        "response_format": "json_object"
      }
    }
  }
}