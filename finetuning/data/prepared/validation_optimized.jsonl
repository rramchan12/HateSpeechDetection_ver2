{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"sexual orientation refers to an enduring pattern of emotional, romantic, and/or sexual attractions to men, women or both sexes.\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"i can â€™ t believe some arabs sexualize wearing pants inside the house around the family embarrassing amp disgusting\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"i realize how precious material life is\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"figure skating ladies and pairs eff the queers\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"the only thing the middle east has given to america is 911\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"MIDDLE_EAST\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"so the ugly bull dyke bullied her classmate shooter leftists are by far some of the most intolerant people on the planet\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"ugly bull dyke\", \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"mexico's a fascinating country with a lot of history\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"if the pearl clutching faggots in sweet home alabamy fuck this up there goes the whole trump agenda\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"nr is not conservative they are just a bunch of retarded cucks no compromise with sexual deviants do not like it move to saudi arabia and find a compromise there\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"the boy scouts are run by fags so its only natural the fags would want dykes to join\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"fags fags dykes\", \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"this is the first time i have ever tried to explore my experience with gender and its cultural differences\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"i would never date a bisexual person because theyre just going to leave you for a man or a woman eventually\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"name must be greek\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"MIDDLE_EAST\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"there is so much i could say, but i think you get the idea.\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"these people should not be allowed in the country. they are doing nothing but making a burden on America. we should be able to put an end to\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"MEXICAN\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"<number> fucks i do not give muff munching wetback commie bitch\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"muff munching wetback commie bitch\", \"protected_group\": \"MEXICAN\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"whoever made this thread has the big gay\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"the city of nashville is allowing a mentally ill trans woman to harass children at a public library and they wont do anything about it\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"a dyke a queer and a jew over there\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"<user> so ppl do not go to church bc i said wearing blue jeans were ghetto not because your great aunt billie mae asked your dyke ass to wear a dress or to stop holding your boyfriend hand on the first pew bc of jeans akskksk i am tired\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"when i was younger i used to shake so much ass because that what we did in down south florida i moved to fort pierce and you can not pay me to because i let bitches tell me what studs dykes do and do not do\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"homosexuality is unacceptable according to God!!!\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"who is this nick fuentes is she some kind of spic jew who wants to be a white nationalist\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"spic jew\", \"protected_group\": \"MEXICAN\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"our country was built by white men, our government is white, and our culture is white. we all came from europe\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"MEXICAN\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"another shit thread bumped up by the gab faggot\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"i will not tolerate non arab women slandering arab men only our camel jockey queens can call us zbele\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"camel jockey queens\", \"protected_group\": \"MIDDLE_EAST\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"arabs are primitive people\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"MIDDLE_EAST\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"I love spicy food. I love the culture and that you really interact with people. I get asked a lot why I enjoy middle eastern food... Just\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"being of mexican ethnicity you identify yourself as mexican\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"and what if we told her that a bunch of misogynnist homophobic anti christian anti semites need to go live with the other arabs that do not want them\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"anti semites need to go live with the other arabs that do not want them\", \"protected_group\": \"MIDDLE_EAST\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"it never really gone out of style it just got kept out of the usual places <number> a while tv media politics academia sand nigger sand groid dune coon dindu nuffin all valuable additions to the nigger lexicon oh sheeit dat remind me mexicon lexicon meh some beaners r ok\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"sand nigger sand groid dune coon dindu nuffin all valuable additions to the nigger lexicon oh sheeit dat remind me mexicon lexicon meh some beaners r ok\", \"protected_group\": \"MIDDLE_EAST\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"if you have a dysphoria you can't change your body because our culture has primed you to be attracted to a certain body\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"The queer identity serves to differentiate queer lgbt individuals from their counterparts in the lgbt community in order to better direct political and social action.\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"i have the merits to become an italian citizen dual and i say deport all sand niggers immediately\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"sand niggers immediately\", \"protected_group\": \"MIDDLE_EAST\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"Middle efrican restaurants are great\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"faggots who put such an extreme emphasis on bourgouise education are like retarded children or maybe more like a normie republican who do not understand nature vs nurture wtf is wrong w you\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"faggots who put such an extreme emphasis on bourgouise education are like retarded children\", \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"arabic food is amazing\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"aryans are superior through their high culture, distinct physical features, advanced technology, and great intelligence. they need to eliminate all opposing inferior races,\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"MIDDLE_EAST\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"the palestinians claim they only want peace but have never accepted a two state solution\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"i would rather i were not a lesbian, and i really wish that i could just not be a lesbian\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"teaching others about the middle eastern cultureÃ‚ middle eastern people create beautiful pieces of artÃ‚ my friends from the middle east help me understand\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"mexican poetry can be sung, spoken, yelled, or even silence and it will still be beautiful\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"you can really tell that gefilte fish was invented by a gay little frog that the peak of juliebait\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"bingo hates americans hates our values hates our country and you civnat faggots pay his tuition\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"i know where they ended up but ashkenazim wherever they are are of that italian me descent was under the impression main change in me na was just arabs replacing mixing with whoever was already there\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"al jizz era wants the white man down we will hang every sand nigger from every street lamp in town before that happens\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"al jizz era wants the white man down we will hang every sand nigger from every street lamp in town before that happens\", \"protected_group\": \"MIDDLE_EAST\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"the redskins is trending is there us teams also called the niggers spics kikes bitches or faggots asking for a friend\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"is there us teams also called the niggers spics kikes bitches or faggots\", \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"an afghani immigrant once told me that in afghanistan we do not believe in fences while our conversation was about livestock guardian dogs it now occurs to me what this really means is that there no belief in protection of persons or property\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"<user> and the same with sexuality if your homophobic pick the straight one\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"spic face gutierrez is talking right now i have had dogs as pets that were smarter than this piece of fucking spic shit\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"spic face gutierrez fucking spic shit\", \"protected_group\": \"MEXICAN\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"if youre a trans man, youre a man, and youre a man who happens to be transgender, not a transgender man.\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{{\"classification\": \"not_hate\", \"confidence\": \"high\", \"reasoning\": \"This text does not contain hate speech.\"}}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"pharma doesn't care about being a slut, just like they don't care about curing cancer\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"stealing is wrong because you are supposed to work for what you have, not take it from others\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"so which are you a faggot or jew or both\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": \"so which are you a faggot or jew or both\", \"protected_group\": \"LGBTQ\"}"}]}
{"messages": [{"role": "system", "content": "You are an expert content moderation assistant trained to classify social media posts as either 'hate' or 'normal' using X platform's hateful conduct policy and community-informed perspectives.\n\nYou MUST respond in strict JSON format with the following structure:\n{\"classification\": \"hate\", \"rationale\": \"brief explanation\"} or {\"classification\": \"normal\", \"rationale\": \"brief explanation\"}\n\nClassification Rules:\n- Use EXACTLY 'hate' if the text violates X's hateful conduct policy OR targets protected communities\n- Use EXACTLY 'normal' if the text does not violate policy AND does not harm protected communities\n- NO other labels are allowed (not 'not_hate', 'hateful', etc.)\n- Always provide a brief rationale (1-2 sentences) explaining your decision\n\nDetection Focus:\n- Direct attacks: Explicit slurs, derogatory terms, and hateful language\n- Coded/subtle hate: Dog whistles, stereotypes, dehumanizing comparisons, and veiled attacks\n- Context matters: Consider whether text criticizes policies/ideas vs. attacks people based on protected characteristics\n- Distinguish community self-reference from external attacks (e.g., LGBTQ+ individuals using in-group terms vs. outsiders using slurs)"}, {"role": "user", "content": "Apply X Platform Hateful Conduct Policy: Content attacking people based on protected characteristics (race, ethnicity, national origin, sexual orientation, gender identity, religion, age, disability) is prohibited. Attacking PEOPLE is hate; criticizing policies/ideologies is not.\n\nCOMMUNITY FOCUS:\n\nLGBTQ+ Community:\n- Slurs targeting sexual orientation/gender identity (both explicit attacks and coded language)\n- Denying LGBTQ+ identities or stereotyping as dangerous/mentally ill\n- Context: LGBTQ+ individuals reclaiming terms (e.g., 'we're queer') is NOT hate; outsiders using same terms to attack IS hate\n\nMexican/Latino Community:\n- Slurs, dehumanization (comparing to animals/diseases/infestations)\n- Immigration-based hate: Generalizing ALL Mexicans as 'illegal', 'criminals', 'invaders', 'rapists', 'job stealers'\n- Coded phrases: 'They're not sending their best', 'go back' when targeting ethnicity (not individual actions)\n- Note: Immigration policy debates are NOT hate unless generalizing/attacking ALL Mexican/Latino people\n\nEXAMPLES - Mexican/Latino Hate vs. Policy Discussion:\nHATE: \"These Mexicans are all illegals, send them back\" (generalizes ALL Mexicans as illegal)\nHATE: \"Mexico isn't sending their best, they're rapists and criminals\" (attacks ALL Mexicans)\nHATE: \"Mexicans are like rats crossing the border\" (dehumanization)\nNORMAL: \"We need stronger border enforcement policies\" (policy discussion, not attacking people)\nNORMAL: \"Immigration system should prioritize legal pathways\" (policy critique)\n\nMiddle Eastern Community:\n- Anti-Arab/anti-Muslim slurs, Islamophobic stereotypes\n- Terrorism generalizations: Assuming ALL Middle Eastern people are terrorists/extremists\n- Distinction: Discussing specific conflicts/groups = NOT hate. Attributing terrorism to ALL Middle Eastern people = hate\n\nText: \"if any of you go on the moffett park forums you will see that moffett park is overpopulated with gangs. they have a\"\n\nEvaluate:\n1. Does it attack PEOPLE based on protected characteristics (vs. criticizing policies)?\n2. Does it use slurs, dehumanization, or harmful generalizations?\n3. Would affected community members reasonably view this as hateful?\n\nClassify:\n- hate (attacks people based on protected characteristics)\n- normal (does not attack protected communities)\n\nRespond in JSON: {\"classification\": \"[hate/normal]\", \"rationale\": \"[cite specific violation or community harm]\"}"}, {"role": "assistant", "content": "{\"classification\": \"hate_speech\", \"confidence\": \"high\", \"reasoning\": null, \"protected_group\": \"LGBTQ\"}"}]}
