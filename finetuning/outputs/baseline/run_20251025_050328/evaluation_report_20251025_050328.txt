HATE SPEECH DETECTION - STRATEGY EVALUATION REPORT
============================================================
Generated: 2025-10-25 05:03:52
Model: openai/gpt-oss-20b
Prompt Template File: default
Data Source: canned_50_quick
Total samples tested: 5

EXECUTION DETAILS:
--------------------
Command Line: /home/azureuser/workspace/HateSpeechDetection_ver2/finetuning/pipeline/baseline/runner.py --max_samples 5

SAMPLE TEST DATA:
--------------------
1. Text: white gay men mad they can not say dyke bc they do not have faggot to themselves lmao
   Label: normal

2. Text: i'm actually a white middle-upper class mexica
   Label: normal

3. Text: √Ç the only thing they know how to make is oil wells and bombs
   Label: hate

[Showing sample of 5 out of 5 total test samples]


STRATEGY PERFORMANCE:
-------------------------

BASELINE Strategy:
  Accuracy:  0.600
  Precision: 0.500
  Recall:    1.000
  F1-Score:  0.667
  Confusion Matrix: TP=2, TN=1, FP=2, FN=0


BIAS AND FAIRNESS METRICS BY PERSONA:
----------------------------------------
üìä FPR = False Positive Rate (benign‚Üíhate misclassification)
üìä FNR = False Negative Rate (hate‚Üíbenign missed detection)
üéØ Lower rates indicate better fairness across personas

BASELINE Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 2
     FPR: 0.500 (FP=1, TN=1)
     FNR: 0.000 (FN=0, TP=0)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 1
     FPR: 1.000 (FP=1, TN=0)
     FNR: 0.000 (FN=0, TP=0)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 2
     FPR: 0.000 (FP=0, TN=0)
     FNR: 0.000 (FN=0, TP=2)
     Fairness: ‚úÖ FAIR
