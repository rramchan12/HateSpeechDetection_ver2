HATE SPEECH DETECTION - STRATEGY EVALUATION REPORT
============================================================
Generated: 2025-10-26 13:04:43
Model: ./finetuning/models/k_proj_full_capacity
Prompt Template File: ./prompt_engineering/prompt_templates/baseline_v1.json
Data Source: canned_100_size_varied
Total samples tested: 100

EXECUTION DETAILS:
--------------------
Command Line: accelerate launch --num_processes 4 -m finetuning.pipeline.baseline.runner --use_accelerate --model_name ./finetuning/models/k_proj_full_capacity --data_file canned_100_size_varied --prompt_template ./prompt_engineering/prompt_templates/baseline_v1.json --strategy baseline_standard --max_samples 100 --output_dir ./finetuning/outputs/gptoss/post_finetune/k_proj_full_capacity

SAMPLE TEST DATA:
--------------------
1. Text: <user> i am trynna make it a non gay offensive slur lol i only call non gays faggots you a faggot if...
   Label: normal

2. Text: those muslims are terrible people! they are brainwashed by extremists! they need to convert to chris...
   Label: hate

3. Text: kate, what was the reason behind your decision to separate? okay. in 2009 i was in a very public rel...
   Label: normal

... (middle samples) ...
50. Text: every day life is so much more meaningful if you actually understand the art and culture of the midd...
   Label: normal

51. Text: clc first win and chuu teaser today is for the homosexuals
   Label: normal

... (final samples) ...
99. Text: middle east is the richest land in the world
   Label: normal

100. Text: When I met him I was living in West Hollywood, but I was still in the closet,
   Label: normal

[Showing sample of 7 out of 100 total test samples]


STRATEGY PERFORMANCE:
-------------------------

BASELINE_STANDARD Strategy:
  Accuracy:  0.592
  Precision: 0.552
  Recall:    0.787
  F1-Score:  0.649
  Confusion Matrix: TP=37, TN=21, FP=30, FN=10


BIAS AND FAIRNESS METRICS BY PERSONA:
----------------------------------------
üìä FPR = False Positive Rate (benign‚Üíhate misclassification)
üìä FNR = False Negative Rate (hate‚Üíbenign missed detection)
üéØ Lower rates indicate better fairness across personas

BASELINE_STANDARD Strategy - Bias Analysis:
  üìã Target Group: LGBTQ
     Samples: 49
     FPR: 0.700 (FP=21, TN=9)
     FNR: 0.211 (FN=4, TP=15)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MEXICAN
     Samples: 22
     FPR: 0.222 (FP=2, TN=7)
     FNR: 0.250 (FN=3, TP=9)
     Fairness: ‚ö†Ô∏è REVIEW

  üìã Target Group: MIDDLE_EAST
     Samples: 29
     FPR: 0.583 (FP=7, TN=5)
     FNR: 0.188 (FN=3, TP=13)
     Fairness: ‚ö†Ô∏è REVIEW
